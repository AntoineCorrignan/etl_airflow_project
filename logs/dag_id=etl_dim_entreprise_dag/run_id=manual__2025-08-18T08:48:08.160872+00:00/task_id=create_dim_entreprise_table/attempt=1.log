{"timestamp":"2025-08-18T08:48:09.084861","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-08-18T08:48:09.085380","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_test.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-18T08:48:09.118283Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T08:48:09.118469Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T08:48:09.118573Z","level":"info","event":"Current task name:create_dim_entreprise_table","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T08:48:09.118654Z","level":"info","event":"Dag name:etl_dim_entreprise_dag","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T08:48:09.119746Z","level":"info","event":"Creating table if not exists...","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T08:48:09.121439","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `from airflow.sdk import Connection` instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-08-18T08:48:09.126965","level":"info","event":"Connection Retrieved 'bdd_neon_recette'","logger":"airflow.hooks.base"}
{"timestamp":"2025-08-18T08:48:09.313061","level":"info","event":"Running statement: \n            CREATE TABLE IF NOT EXISTS dim_entreprise (\n                id VARCHAR(255),\n                siret VARCHAR(255),\n                tva_number VARCHAR(255),\n                address VARCHAR(255),\n                city VARCHAR(255),\n                country VARCHAR(255),\n                region VARCHAR(255),\n                zip_code VARCHAR(255)\n            );\n        , parameters: None","logger":"airflow.task.hooks.airflow.providers.postgres.hooks.postgres.PostgresHook"}
{"timestamp":"2025-08-18T08:48:10.016040Z","level":"info","event":"Table dim_entreprise created or already exists","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T08:48:10.016095","level":"info","event":"Done. Returned value was: Table creation successful","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-08-18T08:48:10.016357","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('0198bc5d-4df9-76cf-bdb5-54d737f7170f'), task_id='create_dim_entreprise_table', dag_id='etl_dim_entreprise_dag', run_id='manual__2025-08-18T08:48:08.160872+00:00', try_number=1, map_index=-1, hostname='c8e28ae48ccc', context_carrier={}, task=<Task(PythonOperator): create_dim_entreprise_table>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=1, start_date=datetime.datetime(2025, 8, 18, 8, 48, 8, 555893, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None, log_url='http://localhost:8080/dags/etl_dim_entreprise_dag/runs/manual__2025-08-18T08%3A48%3A08.160872%2B00%3A00/tasks/create_dim_entreprise_table?try_number=1')","logger":"task"}
{"timestamp":"2025-08-18T08:48:10.045636Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T08:48:10.045845Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T08:48:10.046051Z","level":"info","event":"Task operator:<Task(PythonOperator): create_dim_entreprise_table>","chan":"stdout","logger":"task"}
