{"timestamp":"2025-08-18T10:07:42.991807","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-08-18T10:07:42.992220","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_test.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-08-18T10:07:43.025871Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T10:07:43.026047Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T10:07:43.026175Z","level":"info","event":"Current task name:create_dim_entreprise_table","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T10:07:43.026256Z","level":"info","event":"Dag name:etl_dim_entreprise_dag","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T10:07:43.027245Z","level":"info","event":"Creating table if not exists...","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T10:07:43.028518","level":"warning","event":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/connection.py:471: DeprecationWarning: Using Connection.get_connection_from_secrets from `airflow.models` is deprecated.Please use `from airflow.sdk import Connection` instead\n  warnings.warn(\n","logger":"py.warnings"}
{"timestamp":"2025-08-18T10:07:43.032751","level":"info","event":"Connection Retrieved 'bdd_neon_recette'","logger":"airflow.hooks.base"}
{"timestamp":"2025-08-18T10:07:43.648797","level":"info","event":"Running statement: \n            CREATE TABLE IF NOT EXISTS dim_entreprise (\n                id VARCHAR(255),\n                siret VARCHAR(255),\n                tva_number VARCHAR(255),\n                address VARCHAR(255),\n                city VARCHAR(255),\n                country VARCHAR(255),\n                region VARCHAR(255),\n                zip_code VARCHAR(255)\n            );\n        , parameters: None","logger":"airflow.task.hooks.airflow.providers.postgres.hooks.postgres.PostgresHook"}
{"timestamp":"2025-08-18T10:07:43.719473Z","level":"info","event":"Table dim_entreprise created or already exists","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T10:07:43.719527","level":"info","event":"Done. Returned value was: Table creation successful","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-08-18T10:07:43.719907","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('0198bca6-25fc-7ebc-bf7e-238cd2c35151'), task_id='create_dim_entreprise_table', dag_id='etl_dim_entreprise_dag', run_id='manual__2025-08-18T10:07:42.052706+00:00', try_number=1, map_index=-1, hostname='c8e28ae48ccc', context_carrier={}, task=<Task(PythonOperator): create_dim_entreprise_table>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=1, start_date=datetime.datetime(2025, 8, 18, 10, 7, 42, 651379, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None, log_url='http://localhost:8080/dags/etl_dim_entreprise_dag/runs/manual__2025-08-18T10%3A07%3A42.052706%2B00%3A00/tasks/create_dim_entreprise_table?try_number=1')","logger":"task"}
{"timestamp":"2025-08-18T10:07:43.765500Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T10:07:43.765632Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","chan":"stdout","logger":"task"}
{"timestamp":"2025-08-18T10:07:43.765768Z","level":"info","event":"Task operator:<Task(PythonOperator): create_dim_entreprise_table>","chan":"stdout","logger":"task"}
